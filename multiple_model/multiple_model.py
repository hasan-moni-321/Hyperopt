import numpy as np 
import pandas as pd 
import cv2, os

from hyperopt import Trials, STATUS_OK, tpe
from hyperas import optim

import tensorflow as tf 
from hyperas.distributions import uniform, choice
from keras.models import Sequential
from keras.layers import Conv2D, Dense, Dropout, Activation, Flatten, MaxPooling2D
from keras.optimizers import SGD, Adam, RMSprop 
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical



def data():
    dataset_path = ["/home/hasan/Data Set/covid19/COVID-19 Radiography Database/train", "/home/hasan/Data Set/covid19/COVID-19 Radiography Database/test"]
    CATEGORIES = ['COVID','NORMAL','Viral Pneumonia']

    train_data = []
    valid_data = []
    for idx, p in enumerate(dataset_path):
        for cls in CATEGORIES:
            path = os.path.join(p, cls) 
            cls_name = CATEGORIES.index(cls) 
            for img in os.listdir(path):
                try:
                    image = cv2.imread(os.path.join(path, img)) 
                    image = cv2.resize(image, (256, 256)) 
                    if idx == 0:
                        train_data.append([image, cls_name]) 
                    if idx == 1:
                        valid_data.append([image, cls_name]) 
                except Exception as e:
                    pass 


    # Training dataset
    train_features = []
    train_labels = []
    for feature, label in train_data:
        train_features.append(feature)
        train_labels.append(label) 

    # Valid dataset
    valid_features = []
    valid_labels = []
    for feature, label in valid_data:
        valid_features.append(feature)
        valid_labels.append(label) 

    # features of train, valid
    x_train = np.array(train_features).reshape(-1, 256, 256, 3)
    x_valid = np.array(valid_features).reshape(-1, 256, 256, 3) 

    # one hot encoding of label data
    y_train = to_categorical(train_labels, 3)
    y_valid = to_categorical(valid_labels, 3)

    datagen = ImageDataGenerator(
                                rescale=1./255,
                                shear_range=.2,
                                zoom_range=.2,
                                featurewise_center=False,  # set input mean to 0 over the dataset
                                samplewise_center=False,  # set each sample mean to 0
                                featurewise_std_normalization=False,  # divide inputs by std of the dataset
                                samplewise_std_normalization=False,  # divide each input by its std
                                zca_whitening=False,  # apply ZCA whitening
                                rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
                                width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                                height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                                horizontal_flip=True,  # randomly flip images
                                vertical_flip=False)  # randomly flip images

    datagen.fit(x_train)
    return datagen, x_train, y_train, x_valid, y_valid


def model(datagen, x_train, y_train, x_valid, y_valid): 

    model = Sequential()
    model.add(Conv2D(64, (5,5), padding='same', input_shape=(256, 256, 3)))
    model.add(Activation('relu'))
    model.add(Conv2D(32, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout({{uniform(0, 1)}}))

    model.add(Conv2D(64, 3, 3, padding='same'))
    model.add(Activation('relu'))
    model.add(Conv2D(64, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout({{uniform(0, 1)}}))

    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(3))
    model.add(Activation('softmax'))

    # let's train the model using SGD + momentum (how original).
    sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)
    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
    rmsprop = RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False)
    model.compile(loss='categorical_crossentropy',
                  optimizer={{choice([sgd, adam, rmsprop])}}, 
                  metrics=['accuracy'])

    callbacks = [
        tf.keras.callbacks.EarlyStopping(patience=2, verbose=1),
        tf.keras.callbacks.ModelCheckpoint(monitor="val_loss", verbose=1)
    ]

    # fit the model on the batches generated by datagen.flow()
    model.fit(datagen.flow(x_train, y_train),
              batch_size=32,
              steps_per_epoch=len(x_train),
              epochs=10,
              validation_data=(x_valid, y_valid),
              validation_steps=len(x_valid),
              callbacks=callbacks) 

    score, acc = model.evaluate(x_valid, y_valid, verbose=0)
    return {'loss': -acc, 'status': STATUS_OK, 'model': model} 



if __name__ == '__main__':

    datagen, x_train, y_train, x_valid, y_valid = data()

    best_run, best_model = optim.minimize(model=model,
                                          data=data,
                                          algo=tpe.suggest,
                                          max_evals=5,
                                          trials=Trials())

    print("Evalutation of best performing model:")
    print(best_model.evaluate(x_valid, y_valid))
    print("Best performing model chosen hyper-parameters:")
    print(best_run)
